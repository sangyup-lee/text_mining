{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6920,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[0].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFGPT2ForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2ForSequenceClassification.\n",
      "\n",
      "All the weights of TFGPT2ForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2ForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialogRPT-updown\")\n",
    "model = TFGPT2ForSequenceClassification.from_pretrained(\"microsoft/DialogRPT-updown\", from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized = tokenizer(X_train, return_tensors=\"np\", max_length=30, padding='max_length', truncation=True)\n",
    "X_test_tokenized = tokenizer(X_test, return_tensors=\"np\", max_length=30, padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(2e-5)\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "checkpoint_filepath = \"./checkpoints/checkpoint_gpt2\"\n",
    "mc = ModelCheckpoint(checkpoint_filepath, monitor='val_loss', mode='min', \n",
    "                     save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 [==============================] - 3035s 76s/step - loss: 0.5878 - accuracy: 0.6319 - val_loss: 0.3677 - val_accuracy: 0.8375\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 3326s 85s/step - loss: 0.3244 - accuracy: 0.8577 - val_loss: 0.2832 - val_accuracy: 0.8755\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 3589s 93s/step - loss: 0.2204 - accuracy: 0.9121 - val_loss: 0.2737 - val_accuracy: 0.8863\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 3332s 85s/step - loss: 0.1494 - accuracy: 0.9448 - val_loss: 0.2578 - val_accuracy: 0.8899\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 4281s 110s/step - loss: 0.1070 - accuracy: 0.9613 - val_loss: 0.2822 - val_accuracy: 0.8935\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 3762s 97s/step - loss: 0.0695 - accuracy: 0.9749 - val_loss: 0.3186 - val_accuracy: 0.9007\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 4145s 106s/step - loss: 0.0509 - accuracy: 0.9811 - val_loss: 0.3715 - val_accuracy: 0.8953\n",
      "Epoch 7: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23539b0a0a0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dict(X_train_tokenized), y_train, epochs=10, batch_size=128, validation_split=0.1, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 170s 4s/step\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(dict(X_test_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.5683296],\n",
       "       [-6.1167245],\n",
       "       [ 3.4054523],\n",
       "       ...,\n",
       "       [ 6.943949 ],\n",
       "       [ 6.7827125],\n",
       "       [ 3.8216572]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_probs=tf.nn.sigmoid(y_preds.logits).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions = [1 if x > 0.5 else 0 for x in prediction_probs ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88       635\n",
      "           1       0.90      0.89      0.89       749\n",
      "\n",
      "    accuracy                           0.89      1384\n",
      "   macro avg       0.88      0.88      0.88      1384\n",
      "weighted avg       0.89      0.89      0.89      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
