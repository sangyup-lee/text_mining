{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "방법2: Conv1D를 적용한 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Korean_movie_reviews_2016.txt', encoding='utf-8') as f:\n",
    "    docs = [doc.strip().split('\\t') for doc in f]\n",
    "    docs = [(doc[0], int(doc[1])) for doc in docs if len(doc) == 2]\n",
    "    texts, labels = zip(*docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = [doc.strip().split() for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = []\n",
    "for words in words_list:\n",
    "    total_words.extend(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "common_words = [ word for word, count in c.most_common(max_features)]\n",
    "# 빈도를 기준으로 상위 20000개의 단어들만 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 단어에 대해서 index 생성하기\n",
    "words_dic ={}\n",
    "for index, word in enumerate(common_words):\n",
    "    words_dic[word]=index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문서를 상위 20000개 단어들에 대해서 index 번호로 표현하기\n",
    "filtered_indexed_words = []\n",
    "for review in words_list:\n",
    "    indexed_words=[]\n",
    "    for word in review:\n",
    "        try:\n",
    "            indexed_words.append(words_dic[word])\n",
    "        except:\n",
    "            pass\n",
    "    filtered_indexed_words.append(indexed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "max_len = 24\n",
    "X = sequence.pad_sequences(filtered_indexed_words, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148845, 24)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "token_emb = 32\n",
    "num_filters = 32\n",
    "patch_size = 4 \n",
    "num_patches = (max_len//patch_size)*(num_filters//patch_size)\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  \n",
    "transformer_layers = 2\n",
    "mlp_head_units = [512, 64]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier():\n",
    "    inputs = layers.Input(shape=(max_len,))\n",
    "\n",
    "    data = layers.Embedding(max_features+1, token_emb)(inputs)\n",
    "    data = layers.Conv1D(num_filters,2,activation='relu',padding='same')(data)\n",
    "    data = tf.expand_dims(data, -1)\n",
    "    patches = Patches(patch_size)(data)\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_classifier = create_vit_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 24)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 24, 32)       640032      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 24, 32)       2080        ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 24, 32, 1)    0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " patches (Patches)              (None, None, 16)     0           ['tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " patch_encoder (PatchEncoder)   (None, 48, 64)       4160        ['patches[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 48, 64)      128         ['patch_encoder[0][0]']          \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 48, 64)      66368       ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 48, 64)       0           ['multi_head_attention[0][0]',   \n",
      "                                                                  'patch_encoder[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 48, 64)      128         ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 48, 128)      8320        ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 48, 128)      0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 48, 64)       8256        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 48, 64)       0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 48, 64)       0           ['dropout_1[0][0]',              \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 48, 64)      128         ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 48, 64)      66368       ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 48, 64)       0           ['multi_head_attention_1[0][0]', \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 48, 64)      128         ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 48, 128)      8320        ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 48, 128)      0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 48, 64)       8256        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 48, 64)       0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 48, 64)       0           ['dropout_3[0][0]',              \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 48, 64)      128         ['add_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 3072)         0           ['layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 3072)         0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 512)          1573376     ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 512)          0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 64)           32832       ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 64)           0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 2)            130         ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,419,138\n",
      "Trainable params: 2,419,138\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vit_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical \n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tfa.optimizers.AdamW(\n",
    "    learning_rate=0.0001, weight_decay=0.0001\n",
    ")\n",
    "vit_classifier.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=1)\n",
    "checkpoint_filepath = \"./checkpoints/checkpoint_vit2\"\n",
    "mc = ModelCheckpoint(checkpoint_filepath, monitor='val_loss', mode='min',\n",
    "                     save_best_only=True,\n",
    "                    save_weights_only=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "524/524 [==============================] - 231s 440ms/step - loss: 0.1944 - accuracy: 0.9281 - val_loss: 0.2768 - val_accuracy: 0.8934\n",
      "Epoch 2/5\n",
      "524/524 [==============================] - 230s 439ms/step - loss: 0.1766 - accuracy: 0.9345 - val_loss: 0.2884 - val_accuracy: 0.8928\n",
      "Epoch 2: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = vit_classifier.fit(\n",
    "    x=X_train,\n",
    "    y=y_train_one_hot,\n",
    "    batch_size=256, \n",
    "    epochs=5,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[mc,es],\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517/517 [==============================] - 11s 20ms/step - loss: 0.2867 - accuracy: 0.8960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2866881191730499, 0.8960033655166626]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_classifier.evaluate(X_test, y_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x236897efbb0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_classifier.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517/517 [==============================] - 10s 20ms/step - loss: 0.2580 - accuracy: 0.8989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2579616904258728, 0.8989056348800659]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_classifier.evaluate(X_test, y_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517/517 [==============================] - 11s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "y_prediction_probs = vit_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89      7798\n",
      "           1       0.90      0.91      0.90      8741\n",
      "\n",
      "    accuracy                           0.90     16539\n",
      "   macro avg       0.90      0.90      0.90     16539\n",
      "weighted avg       0.90      0.90      0.90     16539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = np.argmax(y_prediction_probs, axis=1)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
