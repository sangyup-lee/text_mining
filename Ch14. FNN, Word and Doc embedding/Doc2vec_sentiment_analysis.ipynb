{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Korean_movie_reviews_2016.txt', encoding='utf-8') as f:\n",
    "    docs = [doc.strip().split('\\t') for doc in f]\n",
    "    docs = [(doc[0], int(doc[1])) for doc in docs if len(doc) == 2]\n",
    "    texts, labels = zip(*docs)\n",
    "    # 둘을 분리해서 별도의 list 변수로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_words = [doc.strip().split() for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['부산', '행', '때문', '너무', '기대하고', '봤'], ['한국', '좀비', '영화', '어색하지', '않게', '만들어졌', '놀랍']]\n"
     ]
    }
   ],
   "source": [
    "print(docs_words[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "tagged_docs = [TaggedDocument(doc, tags=[i]) for i, doc in enumerate(docs_words) if doc != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['부산', '행', '때문', '너무', '기대하고', '봤'], tags=[0]),\n",
       " TaggedDocument(words=['한국', '좀비', '영화', '어색하지', '않게', '만들어졌', '놀랍'], tags=[1])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_docs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(tagged_docs, vector_size=100, min_count=3, window=3, epochs=100, dm=1, negative=5, \n",
    "               alpha=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165384"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165384"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165384"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'부산 행 때문 너무 기대하고 봤'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.753497"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.dot(model.dv[89881], model.dv[0])/(np.linalg.norm(model.dv[89881])*np.linalg.norm(model.dv[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reivew ID: 89881, review: 호평 때문 기대하고 봤 기대 초과, similarity: 0.7534970641136169\n",
      "reivew ID: 102986, review: 영 상미 넘 예쁨 애기 때문 빵빵 터졌, similarity: 0.7008088231086731\n",
      "reivew ID: 161929, review: 화끈 액션 씬 때문 손 땀 나더, similarity: 0.6940357089042664\n",
      "reivew ID: 10810, review: 시종일관 화려한 스케일 때문 눈 떼지 했, similarity: 0.6846963763237\n",
      "reivew ID: 106992, review: 오베 남자 때문 울 웃다, similarity: 0.6795190572738647\n",
      "reivew ID: 14517, review: 도대체 왜 때문, similarity: 0.6789843440055847\n",
      "reivew ID: 155429, review: 음 부산 행 때문 보시 분 굳이 보실 필요 없 것 같아, similarity: 0.674677848815918\n",
      "reivew ID: 7252, review: 흥미로운 스토리 때문 눈 뗄 수 없었, similarity: 0.6687542200088501\n",
      "reivew ID: 45464, review: 지루한 부분 때문 기대 미치, similarity: 0.6607589721679688\n",
      "reivew ID: 54255, review: 다양한 캐릭터 때문 보는 재미 쏠쏠 했, similarity: 0.6599541306495667\n"
     ]
    }
   ],
   "source": [
    "for id, sim in model.dv.most_similar(0, topn=10):\n",
    "    print('reivew ID: {}, review: {}, similarity: {}'.format(id, texts[id],sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_vectors = []\n",
    "for i in range(len(texts)):\n",
    "    docs_vectors.append(model.dv[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165384"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(docs_vectors, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132307 132307\n"
     ]
    }
   ],
   "source": [
    "print(len(train_features), len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LogisticRegression(C=1, penalty='l2', solver='saga') \n",
    "lr2.fit(train_features, train_labels) \n",
    "pred_labels = lr2.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' % accuracy_score(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "lr1 = LogisticRegression(C=1, penalty='l1', solver='saga') \n",
    "lr1.fit(train_features, train_labels) \n",
    "pred_labels = lr1.predict(test_features)\n",
    "print('Accuracy: %.2f' % accuracy_score(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
